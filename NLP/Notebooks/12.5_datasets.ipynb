{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "pytorch_venv",
   "display_name": "Python 3.8.5 64-bit ('pytorch_venv': conda)"
  },
  "interpreter": {
   "hash": "d5d34090966ca49d3fd732d53488c8e7238a38973dcb52264c8827cd995a5aab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "986"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from datasets import list_datasets\n",
    "datasets_list = list_datasets()\n",
    "len(datasets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "acronym_identification, ade_corpus_v2, adversarial_qa, aeslc, afrikaans_ner_corpus, ag_news, ai2_arc, air_dialogue, ajgt_twitter_ar, allegro_reviews, allocine, alt, amazon_polarity, amazon_reviews_multi, amazon_us_reviews, ambig_qa, amttl, anli, app_reviews, aqua_rat, aquamuse, ar_cov19, ar_res_reviews, ar_sarcasm, arabic_billion_words, arabic_pos_dialect, arabic_speech_corpus, arcd, arsentd_lev, art, arxiv_dataset, ascent_kb, aslg_pc12, asnq, asset, assin, assin2, atomic, autshumato, babi_qa, banking77, bbaw_egyptian, bbc_hindi_nli, bc2gm_corpus, best2009, bianet, bible_para, big_patent, billsum, bing_coronavirus_query_set, biomrc, blended_skill_talk, blimp, blog_authorship_corpus, bn_hate_speech, bookcorpus, bookcorpusopen, boolq, bprec, break_data, brwac, bsd_ja_en, bswac, c3, c4, cail2018, caner, capes, catalonia_independence, cawac, cbt, cc100, cc_news, ccaligned_multilingual, cdsc, cdt, cfq, chr_en, cifar10, cifar100, circa, civil_comments, clickbait_news_bg, climate_fever, clinc_oos, clue, cmrc2018, cnn_dailymail, coached_conv_pref, coarse_discourse, codah, code_search_net, code_x_glue_cc_clone_detection_big_clone_bench, code_x_glue_cc_clone_detection_poj104, code_x_glue_cc_cloze_testing_all, code_x_glue_cc_cloze_testing_maxmin, code_x_glue_cc_code_completion_line, code_x_glue_cc_code_completion_token, code_x_glue_cc_code_refinement, code_x_glue_cc_code_to_code_trans, code_x_glue_cc_defect_detection, code_x_glue_ct_code_to_text, code_x_glue_tc_nl_code_search_adv, code_x_glue_tc_text_to_code, code_x_glue_tt_text_to_text, com_qa, common_gen, common_voice, commonsense_qa, compguesswhat, conceptnet5, conll2000, conll2002, conll2003, conllpp, conv_ai, conv_ai_2, conv_ai_3, conv_questions, coqa, cord19, cornell_movie_dialog, cos_e, cosmos_qa, counter, covid_qa_castorini, covid_qa_deepset, covid_qa_ucsd, covid_tweets_japanese, covost2, craigslist_bargains, crawl_domain, crd3, crime_and_punish, crows_pairs, cryptonite, cs_restaurants, cuad, curiosity_dialogs, daily_dialog, dane, danish_political_comments, dart, datacommons_factcheck, dbpedia_14, dbrd, deal_or_no_dialog, definite_pronoun_resolution, dengue_filipino, dialog_re, diplomacy_detection, disaster_response_messages, discofuse, discovery, doc2dial, docred, doqa, dream, drop, duorc, dutch_social, dyk, e2e_nlg, e2e_nlg_cleaned, ecb, ecthr_cases, eduge, ehealth_kd, eitb_parcc, eli5, emea, emo, emotion, emotone_ar, empathetic_dialogues, enriched_web_nlg, eraser_multi_rc, esnli, eth_py150_open, ethos, eu_regulatory_ir, eurlex, euronews, europa_eac_tm, europa_ecdc_tm, europarl_bilingual, event2Mind, evidence_infer_treatment, exams, factckbr, fake_news_english, fake_news_filipino, farsi_news, fashion_mnist, fever, few_rel, financial_phrasebank, finer, flores, flue, fquad, freebase_qa, gap, gem, generated_reviews_enth, generics_kb, german_legal_entity_recognition, germaner, germeval_14, giga_fren, gigaword, glucose, glue, gnad10, go_emotions, gooaq, google_wellformed_query, grail_qa, great_code, guardian_authorship, gutenberg_time, hans, hansards, hard, harem, has_part, hate_offensive, hate_speech18, hate_speech_filipino, hate_speech_offensive, hate_speech_pl, hate_speech_portuguese, hatexplain, hausa_voa_ner, hausa_voa_topics, hda_nli_hindi, head_qa, health_fact, hebrew_projectbenyehuda, hebrew_sentiment, hebrew_this_world, hellaswag, hendrycks_test, hind_encorp, hindi_discourse, hippocorpus, hkcancor, hlgd, hope_edi, hotpot_qa, hover, hrenwac_para, hrwac, humicroedit, hybrid_qa, hyperpartisan_news_detection, iapp_wiki_qa_squad, id_clickbait, id_liputan6, id_nergrit_corpus, id_newspapers_2018, id_panl_bppt, id_puisi, igbo_english_machine_translation, igbo_monolingual, igbo_ner, ilist, imdb, imdb_urdu_reviews, imppres, indic_glue, indonlu, inquisitive_qg, interpress_news_category_tr, interpress_news_category_tr_lite, irc_disentangle, isixhosa_ner_corpus, isizulu_ner_corpus, iwslt2017, jeopardy, jfleg, jigsaw_toxicity_pred, jnlpba, journalists_questions, kannada_news, kd_conv, kde4, kelm, kilt_tasks, kilt_wikipedia, kinnews_kirnews, klue, kor_3i4k, kor_hate, kor_ner, kor_nli, kor_nlu, kor_qpair, kor_sae, kor_sarcasm, labr, lama, lambada, large_spanish_corpus, laroseda, lc_quad, lener_br, liar, librispeech_asr, librispeech_lm, limit, lince, linnaeus, liveqa, lj_speech, lm1b, lst20, m_lama, mac_morpho, makhzan, masakhaner, math_dataset, math_qa, matinf, mc_taco, md_gender_bias, mdd, med_hop, medal, medical_dialog, medical_questions_pairs, menyo20k_mt, meta_woz, metooma, metrec, miam, mkb, mkqa, mlqa, mlsum, mnist, mocha, moroco, movie_rationales, mrqa, ms_marco, ms_terms, msr_genomics_kbcomp, msr_sqa, msr_text_compression, msr_zhen_translation_parity, msra_ner, mt_eng_vietnamese, muchocine, multi_booked, multi_news, multi_nli, multi_nli_mismatch, multi_para_crawl, multi_re_qa, multi_woz_v22, multi_x_science_sum, mutual_friends, mwsc, myanmar_news, narrativeqa, narrativeqa_manual, natural_questions, ncbi_disease, nchlt, ncslgr, nell, neural_code_search, news_commentary, newsgroup, newsph, newsph_nli, newspop, newsqa, newsroom, nkjp-ner, nli_tr, nlu_evaluation_data, norec, norne, norwegian_ner, nq_open, nsmc, numer_sense, numeric_fused_head, oclar, offcombr, offenseval2020_tr, offenseval_dravidian, ofis_publik, ohsumed, ollie, omp, onestop_english, open_subtitles, openbookqa, openslr, openwebtext, opinosis, opus100, opus_books, opus_dgt, opus_dogc, opus_elhuyar, opus_euconst, opus_finlex, opus_fiskmo, opus_gnome, opus_infopankki, opus_memat, opus_montenegrinsubs, opus_openoffice, opus_paracrawl, opus_rf, opus_tedtalks, opus_ubuntu, opus_wikipedia, opus_xhosanavy, orange_sum, oscar, para_crawl, para_pat, parsinlu_reading_comprehension, paws, paws-x, pec, peer_read, peoples_daily_ner, per_sent, persian_ner, pg19, php, piaf, pib, piqa, pn_summary, poem_sentiment, polemo2, poleval2019_cyberbullying, poleval2019_mt, polsum, polyglot_ner, prachathai67k, pragmeval, proto_qa, psc, ptb_text_only, pubmed, pubmed_qa, py_ast, qa4mre, qa_srl, qa_zre, qangaroo, qanta, qasc, qasper, qed, qed_amara, quac, quail, quarel, quartz, quora, quoref, race, re_dial, reasoning_bg, recipe_nlg, reclor, reddit, reddit_tifu, refresd, reuters21578, ro_sent, ro_sts, ro_sts_parallel, roman_urdu, ronec, ropes, rotten_tomatoes, s2orc, samsum, sanskrit_classic, saudinewsnet, scan, scb_mt_enth_2020, schema_guided_dstc8, scicite, scielo, scientific_papers, scifact, sciq, scitail, scitldr, search_qa, selqa, sem_eval_2010_task_8, sem_eval_2014_task_1, sem_eval_2020_task_11, sent_comp, senti_lex, senti_ws, sentiment140, sepedi_ner, sesotho_ner_corpus, setimes, setswana_ner_corpus, sharc, sharc_modified, sick, silicone, simple_questions_v2, siswati_ner_corpus, smartdata, sms_spam, snips_built_in_intents, snli, snow_simplified_japanese_corpus, so_stacksample, social_bias_frames, social_i_qa, sofc_materials_articles, sogou_news, spanish_billion_words, spc, species_800, spider, squad, squad_adversarial, squad_es, squad_it, squad_kor_v1, squad_kor_v2, squad_v1_pt, squad_v2, squadshifts, srwac, sst, stereoset, stsb_mt_sv, stsb_multi_mt, style_change_detection, subjqa, super_glue, swag, swahili, swahili_news, swda, swedish_ner_corpus, swedish_reviews, tab_fact, tamilmixsentiment, tanzil, tapaco, tashkeela, taskmaster1, taskmaster2, taskmaster3, tatoeba, ted_hrlr, ted_iwlst2013, ted_multi, ted_talks_iwslt, telugu_books, telugu_news, tep_en_fa_para, thai_toxicity_tweet, thainer, thaiqa_squad, thaisum, tilde_model, times_of_india_news_headlines, timit_asr, tiny_shakespeare, tlc, tmu_gfm_dataset, totto, trec, trivia_qa, tsac, ttc4900, tunizi, tuple_ie, turk, turkish_movie_sentiment, turkish_ner, turkish_product_reviews, turkish_shrinked_ner, turku_ner_corpus, tweet_eval, tweet_qa, tweets_ar_en_parallel, tweets_hate_speech_detection, twi_text_c3, twi_wordsim353, tydiqa, ubuntu_dialogs_corpus, udhr, um005, un_ga, un_multi, un_pc, universal_dependencies, universal_morphologies, urdu_fake_news, urdu_sentiment_corpus, web_nlg, web_of_science, web_questions, weibo_ner, wi_locness, wiki40b, wiki_asp, wiki_atomic_edits, wiki_auto, wiki_bio, wiki_dpr, wiki_hop, wiki_lingua, wiki_movies, wiki_qa, wiki_qa_ar, wiki_snippets, wiki_source, wiki_split, wiki_summary, wikiann, wikicorpus, wikihow, wikipedia, wikisql, wikitext, wikitext_tl39, wili_2018, wino_bias, winograd_wsc, winogrande, wiqa, wisesight1000, wisesight_sentiment, wmt14, wmt15, wmt16, wmt17, wmt18, wmt19, wmt20_mlqe_task1, wmt20_mlqe_task2, wmt20_mlqe_task3, wmt_t2t, wnut_17, wongnai_reviews, woz_dialogue, wrbsc, x_stance, xcopa, xed_en_fi, xglue, xnli, xor_tydi_qa, xquad, xquad_r, xsum, xsum_factuality, xtreme, yahoo_answers_qa, yahoo_answers_topics, yelp_polarity, yelp_review_full, yoruba_bbc_topics, yoruba_gv_ner, yoruba_text_c3, yoruba_wordsim353, youtube_caption_corrections, zest, AConsApart/anime_subtitles_DialoGPT, Abdo1Kamr/Arabic_Nine_Hadiths_Books, AdWeeb/DravidianMT, Adnan/Urdu_News_Headlines, Akshith/aa, Akshith/g_rock, Akshith/test, Annielytics/DoctorsNotes, Avishekavi/Avi, Binbin/my_dataset, Cropinky/flatearther, Cropinky/wow_fishing_bobber, Darren/data, EMBO/biolang, EMBO/sd-nlp, Eymen3455/xsum_tr, FRTNX/cosuju, Felix-ML/quoteli3, Firoj/CrisisBench, Fraser/mnist-text-default, Fraser/mnist-text-no-spaces, Fraser/mnist-text-small, Fraser/news-category-dataset, Fraser/python-lines, Fraser/short-jokes, GalacticAI/Noirset, Halilyesilceng/autonlp-data-nameEntityRecognition, HarleyQ/WitcherDialogue, Harveenchadha/Gujarati-Monolingual-Data, Jean-Baptiste/wikiner_fr, KETI-AIR/klue, KETI-AIR/kor_corpora, KETI-AIR/korquad, KETI-AIR/nikl, LIAMF-USP/arc-retrieval-c4, MKK/Dhivehi-English, MarianaSahagun/test, Melinoe/TheLabTexts, NTUYG/RAGTest, NbAiLab/norec_agg, NbAiLab/norne, NbAiLab/norwegian_parliament, Ofrit/tmp, QA/abk-eng, Remesita/tagged_reviews, SCourthial/test, SajjadAyoubi/persian_qa, Shreesha/discord-rick-bot, TRoboto/masc, Tatyana/ru_sentiment_dataset, Terry0107/RiSAWOZ, TimTreasure4/Test, Trainmaster9977/957, Trainmaster9977/zbakuman, Tyler/wikimatrix_collapsed, Valahaar/wsdmt, Vishva/UniFAQ_DataSET, Wikidepia/IndoParaCrawl, Wikidepia/IndoSQuAD, XiangXiang/clt, Yves/fhnw_swiss_parliament, abhishek/autonlp-data-imdb_eval, abwicke/C-B-R, abwicke/koplo, adamlin/re_dial, ajmbell/test-dataset, alireza655/alireza655, allenai/c4, anukaver/EstQA, ashish-shrivastava/dont-know-dataset, astarostap/antisemitic-tweets, astarostap/antisemitic_tweets, athivvat/thai-rap-lyrics, ausgequetschtem/jtrddfhfgh, bavard/personachat_truecased, bemanningssitua/dplremjfjfj, berkergurcay/2020-10K-Reports, bsc/ancora-ca-ner, bsc/sts-ca, bsc/tecla, bsc/viquiquad, bsc/xquad-ca, caca/zscczs, canwenxu/dogwhistle, ccccccc/hdjw_94ejrjr, cdminix/mgb1, cemigo/taylor_vs_shakes, cemigo/test-data, chenyuxuan/few-nerd, cheulyop/ksponspeech, clarin-pl/cst-wikinews, clarin-pl/nkjp-pos, clarin-pl/polemo2-official, classla/copa_hr, classla/hr500k, classla/reldi_hr, classla/reldi_sr, classla/setimes_sr, cnrcastroli/aaaa, cointegrated/ParaNMT-Ru-Leipzig, congpt/dstc23_asr, corypaik/prost, ctl/ConceptualCaptions, dasago78/dasago78dataset, dataset/wikipedia_bn, david-wb/zeshel, deepset/germandpr, deepset/germanquad, dfgvhxfgv/fghghj, dgknrsln/Yorumsepeti, dispenst/jhghdghfd, dispix/test-dataset, dk-crazydiv/huggingface-modelhub, dynabench/dynasent, dynabench/qa, eason929/test, edfews/szdfcszdf, edsas/fgrdtgrdtdr, edsas/grttyi, ervis/aaa, ervis/qqq, fatvvs/autonlp-data-entity_model_conll2003, flax-sentence-embeddings/paws-jsonl, flax-sentence-embeddings/stackexchange_title_body_jsonl, flax-sentence-embeddings/stackexchange_xml, formermagic/github_python_1m, formu/CVT, fulai/DuReader, fuliucansheng/data_for_test, fuliucansheng/mininlp, fuliucansheng/pascal_voc, fvillena/cantemist, fvillena/spanish_diagnostics, german-nlp-group/german_common_crawl, godzillavskongonlinetv/ergfdg, godzillavskongonlinetv/godzillavskongfullmovie, gpt3mix/rt20, gpt3mix/sst2, gustavecortal/fr_covid_news, hartzeer/kdfjdshfje, hfface/poopi, huggingFaceUser02/air21_grp13_inference_results, huggingFaceUser02/air21_grp13_tokenized_results, huseinzol05/translated-The-Pile, iamshsdf/sssssssssss, iarfmoose/question_generator, imthanhlv/binhvq_news21_raw, jaimin/wav2vec2-large-xlsr-gujarati-demo, jdepoix/junit_test_completion, jglaser/binding_affinity, jimregan/clarinpl_sejmsenat, jimregan/clarinpl_studio, jiyoojeong/targetizer, jmamou/augmented-glue-sst2, joelito/ler, joelito/sem_eval_2010_task_8, julien-c/dummy-dataset-from-colab, julien-c/reactiongif, k-halid/ar, karinev/lanuitdudroit, katoensp/VR-OP, kmyoo/klue-tc-dev, lavis-nlp/german_legal_sentences, lewtun/binary_classification_dummy, lewtun/mnist-preds, lewtun/text_classification_dummy, lhoestq/custom_squad, lhoestq/squad, lhoestq/test, lhoestq/wikipedia_bn, lkiouiou/o9ui7877687, lohanna/testedjkcxkf, lucien/sciencemission, lucien/voacantonesed, lucien/wsaderfffjjjhhh, lucio/common_voice_eval, mad/IndonesiaNewsDataset, majod/CleanNaturalQuestionsDataset, makanan/umich, medzaf/test, metalearning/kaggale-nlp-tutorial, mksaad/Arabic_news, mldmm/glass_alloy_composition, mmm-da/rutracker_anime_torrent_titles, mrojas/abbreviation, mrojas/body, mrojas/disease, mrojas/family, mrojas/finding, mrojas/medication, mrojas/procedure, mulcyber/europarl-mono, mustafa12/db_ee, mustafa12/edaaaas, mustafa12/thors, nateraw/cats-and-dogs, nateraw/fairface, nateraw/test, naver-clova-conversation/klue-tc-dev-tsv, naver-clova-conversation/klue-tc-tsv, naver-clova-conversation-ul/klue-tc-dev, nbroad/few-nerd, nucklehead/ht-voice-dataset, oelkrise/CRT, osanseviero/llama_test, osanseviero/test, parivartanayurveda/Malesexproblemsayurvedictreatment, pasinit/xlwic, patrickvonplaten/librispeech_asr_dummy, patrickvonplaten/scientific_papers_dummy, pdesoyres/test, peixian/equity_evaluation_corpus, peixian/rtGender, pelican/test_100, persiannlp/parsinlu_entailment, persiannlp/parsinlu_query_paraphrasing, persiannlp/parsinlu_reading_comprehension, persiannlp/parsinlu_sentiment, persiannlp/parsinlu_translation_en_fa, persiannlp/parsinlu_translation_fa_en, piEsposito/br-quad-2.0, piEsposito/br_quad_20, piEsposito/squad_20_ptbr, princeton-nlp/datasets-for-simcse, priya3301/Graduation_admission, priya3301/tes, priya3301/test, rewardsignal/reddit_writing_prompts, rony/soccer-dialogues, roskoN/dstc8-reddit-corpus, sagnikrayc/mctest, sagnikrayc/quasar, salesken/Paraphrase_category_detection, sdfufygvjh/fgghuviugviu, seamew/ChnSentiCorp, seamew/Hotel, seamew/THUCNews, seamew/Weibo, seamew/amazon_reviews_zh, seamew/weibo_avg, shahrukhx01/questions-vs-statements, sharejing/BiPaR, sileod/metaeval, sismetanin/rureviews, smallv0221/my-test, somaimanguyat/Genjer, somaimanguyat/Koboy, somaimanguyat/Movieonline2021, somaimanguyat/Salome, somaimanguyat/movie21, somaimanguyat/xiomay, spacemanidol/ms_marco_doc2query, spacemanidol/msmarco_passage_ranking, ssasaa/gghghgh, sshleifer/pseudo_bart_xsum, stas/openwebtext-10k, stas/wmt14-en-de-pre-processed, stas/wmt16-en-ro-pre-processed, stiel/skjdhjkasdhasjkd, subiksha/OwnDataset, susumu2357/squad_v2_sv, svalabs/all-nli-german-translation-wmt19, svalabs/ms-marco-german-translation-wmt19, tals/test, tarudesu/UIT-ViCTSD, thiemowa/argumentationreviewcorpus, thiemowa/empathyreviewcorpus, tommy19970714/common_voice, turingbench/TuringBench, uasoyasser/rgfes, uva-irlab/canard_quretec, vasudevgupta/bigbird-tokenized-natural-questions, vasudevgupta/data, vasudevgupta/gsoc-librispeech, vasudevgupta/natural-questions-validation, vasudevgupta/temperature-distribution-2d-plate, vasudevgupta/temperature-distribution-3d-cylinder, vblagoje/wikipedia_snippets_streamed, vctc92/sdsd, vctc92/test, versae/adobo, vershasaxena91/datasets, vershasaxena91/squad_multitask, w-nicole/childes_data, w-nicole/childes_data_no_tags, w-nicole/childes_data_no_tags_, w-nicole/childes_data_with_tags, w-nicole/childes_data_with_tags_, w11wo/imdb-javanese, webek18735/ddvoacantonesed, webek18735/dhikhscook, weijieliu/senteval_cn, wmt/europarl, wmt/news-commentary, wmt/uncorpus, wmt/wikititles, wmt/wmt10, wmt/wmt13, wmt/wmt14, wmt/wmt15, wmt/wmt16, wmt/wmt17, wmt/wmt18, wmt/wmt19, yluisfern/PBU\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(dataset for dataset in datasets_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading and preparing dataset squad_es/v1.1.0 (download: 37.47 MiB, generated: 90.25 MiB, post-processed: Unknown size, total: 127.72 MiB) to /home/jnavio/.cache/huggingface/datasets/squad_es/v1.1.0/1.1.0/bcada4f600192451443b95e24f609325705c5185b8aad97bffa8bc3784a867ad...\n",
      "Downloading: 33.9MB [00:06, 5.35MB/s]\n",
      "Downloading: 5.35MB [00:02, 2.20MB/s]\n",
      "                                          Dataset squad_es downloaded and prepared to /home/jnavio/.cache/huggingface/datasets/squad_es/v1.1.0/1.1.0/bcada4f600192451443b95e24f609325705c5185b8aad97bffa8bc3784a867ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'train': (87595, 5), 'validation': (10570, 5)}"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset('squad_es','v1.1.0')\n",
    "raw_datasets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answers', 'context', 'id', 'question', 'title'],\n",
       "        num_rows: 87595\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['answers', 'context', 'id', 'question', 'title'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'answers': {'text': ['sthène', 'sthène', 'sthène', 'sthène', 'sthène'],\n",
       "  'answer_start': [746, 746, 746, 746, 746]},\n",
       " 'context': 'La fuerza de la libra tiene una contraparte métrica, menos utilizada que el newton: El kilogramo (kgf) (a veces kilopond), es la fuerza ejercida por la gravedad estándar en un kilogramo de masa. La fuerza de kilogramo conduce a una unidad de masa alternativa, pero rara vez utilizada: La babosa métrica (a veces llamada mug o Hyl) es la masa que se acelera a 1 m · s − 2 cuando se somete. El kilogramo de fuerza no es parte del sistema moderno SI, y generalmente es obsoleto. Sin embargo, todavía se utiliza para algunos propósitos como la expresión del peso de la aeronave, el empuje de los aviones, la bicicleta habló tensión, la configuración de la llave de par motor y el par de salida del motor. Otras unidades de fuerza arcanas incluyen el sthène, que es equivalente a 1000 N, y el kip, que es equivalente a 1000 lbf.',\n",
       " 'id': '5737aafd1c456719005744ff',\n",
       " 'question': '¿Cuál es la unidad de fuerza rara vez utilizada igual a mil newtons?',\n",
       " 'title': 'Fuerza'}"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "raw_datasets['validation'][10569]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'answers': {'text': ['ciudad metropolitana de Katmandú'],\n",
       "  'answer_start': [3]},\n",
       " 'context': \"La ciudad metropolitana de Katmandú (KMC), con el fin de promover las relaciones internacionales, ha establecido una Secretaría de Relaciones Internacionales (IRC). La primera relación internacional de KMC se estableció en 1975 con la ciudad de Eugene, Oregón, Estados Unidos. Esta actividad se ha mejorado aún más al establecer relaciones formales con otras 8 ciudades: Motsumoto City de Japón, Rochester de Estados Unidos, Yangon (anteriormente Rangoon) de Myanmar, Xi 'an de la República Popular de China. El esfuerzo constante de KMC es mejorar su interacción con los países de SAARC, otras agencias internacionales y muchas otras ciudades importantes del mundo para lograr mejores programas de gestión urbana y desarrollo para Katmandú.\",\n",
       " 'id': '5735d259012e2f140011a0a1',\n",
       " 'question': '¿De qué es KMC un inicialismo?',\n",
       " 'title': 'Katmandú.'}"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "raw_datasets['train'][87594]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Universidad _ de _ Notre _ Dame',\n",
       " 'Universidad _ de _ Notre _ Dame',\n",
       " 'Universidad _ de _ Notre _ Dame',\n",
       " 'Universidad _ de _ Notre _ Dame',\n",
       " 'Universidad _ de _ Notre _ Dame']"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "raw_datasets['train']['title'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None),\n",
       " 'context': Value(dtype='string', id=None),\n",
       " 'id': Value(dtype='string', id=None),\n",
       " 'question': Value(dtype='string', id=None),\n",
       " 'title': Value(dtype='string', id=None)}"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "raw_datasets['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None),\n",
       " 'context': Value(dtype='string', id=None),\n",
       " 'id': Value(dtype='string', id=None),\n",
       " 'question': Value(dtype='string', id=None),\n",
       " 'title': Value(dtype='string', id=None)}"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "raw_datasets['validation'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 10.4kB/s]\n",
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 274kB/s]\n",
      "Downloading: 100%|██████████| 213k/213k [00:00<00:00, 530kB/s]\n",
      "Downloading: 100%|██████████| 436k/436k [00:00<00:00, 482kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example['context'], example['question'], padding = 'max_length', truncation = True, max_length = 128\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 88/88 [00:33<00:00,  2.59ba/s]\n",
      "100%|██████████| 11/11 [00:04<00:00,  2.63ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'train': ['answers', 'attention_mask', 'context', 'id', 'input_ids', 'question', 'title', 'token_type_ids'], 'validation': ['answers', 'attention_mask', 'context', 'id', 'input_ids', 'question', 'title', 'token_type_ids']}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [165, 165, 165]}, 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'context': 'El Super Bowl 50 fue un partido de fútbol americano para determinar al campeón de la NFL para la temporada 2015. El campeón de la American Football Conference (AFC) Denver Broncos derrotó al campeón de la National Football Conference (NFC) Carolina Panthers 24-10 para ganar su tercer título de Super Bowl. El partido se jugó el 7 de febrero de 2016 en el Levi \\'s Stadium en la Bahía de San Francisco en Santa Clara, California. Como este fue el 50º Super Bowl, la liga enfatizó el \"aniversario dorado\" con varias iniciativas temáticas de oro, así como suspender temporalmente la tradición de nombrar cada juego de Super Bowl con números romanos (bajo los cuales el juego).', 'id': '56be4db0acb8001400a502ec', 'input_ids': [101, 2896, 3198, 5308, 1851, 175, 4175, 8362, 1226, 12894, 1260, 175, 12643, 1204, 15792, 1821, 26237, 7428, 18311, 1260, 2083, 14503, 1197, 2393, 3227, 1162, 4722, 1260, 2495, 4279, 18311, 2495, 16655, 22077, 1410, 119, 2896, 3227, 1162, 4722, 1260, 2495, 1237, 2289, 3047, 113, 10402, 114, 7068, 14722, 4167, 10595, 7774, 2393, 3227, 1162, 4722, 1260, 2495, 1305, 2289, 3047, 113, 24743, 114, 2938, 13598, 1572, 118, 1275, 18311, 176, 3906, 1197, 28117, 21359, 19878, 1200, 189, 6212, 7926, 2858, 1260, 3198, 5308, 119, 2896, 1226, 12894, 14516, 179, 9610, 7774, 8468, 128, 1260, 175, 15581, 14906, 1186, 1260, 1446, 4035, 8468, 12388, 112, 102, 225, 154, 22476, 174, 18276, 5674, 1260, 2495, 4279, 4248, 7774, 170, 2495, 10402, 4035, 8468, 3198, 5308, 1851, 136, 102], 'question': '¿Qué equipo de la NFL representó a la AFC en el Super Bowl 50?', 'title': 'Super Bowl _ 50', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets['validation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'attention_mask', 'context', 'input_ids', 'question', 'token_type_ids'],\n",
       "    num_rows: 10570\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns(['title','id'])\n",
    "tokenized_datasets = tokenized_datasets.with_format('torch')\n",
    "tokenized_datasets['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets['validation'].select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'attention_mask', 'context', 'input_ids', 'question', 'token_type_ids'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "small_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'small_train_dataset' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c16262fe16bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msmall_train_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'small_train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "small_train_dataset.to_dict()['context'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}